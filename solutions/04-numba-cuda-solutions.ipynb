{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sapphire-virgin",
   "metadata": {},
   "source": [
    "# Introduction to GPU Programming with Python\n",
    "## Solutions to notebook 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb257512-616d-415e-a169-77c42b60ebc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Main example: Matrix multiplication using Numba CUDA (in global memory only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c44b6-452a-4165-9bd5-8b13854cd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99deb61b-65f5-43f1-89e2-a700686b8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Create matrices A,B,C as numpy arrays. Fill A and B with random numbers.\n",
    "A=np.random.rand(512,512).astype(np.float32)\n",
    "B=np.random.rand(512,512).astype(np.float32)\n",
    "C=np.zeros(shape=(512,512)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589497f-adc8-4d3a-93f7-433127907756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Calculate number of blocks and threads\n",
    "NumThreads=32\n",
    "NumBlocks = (C.shape[0]+(NumThreads-1))//NumThreads\n",
    "blockdim = (NumThreads,NumThreads)\n",
    "griddim = (NumBlocks,NumBlocks)\n",
    "print(griddim,blockdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e790b5-21db-4336-acdf-443af782d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Create a CUDA kernel with @cuda.jit decorator\n",
    "@cuda.jit\n",
    "def matmul(A,B,C):\n",
    "    i,j=cuda.grid(2)\n",
    "    if i<C.shape[0] and j<C.shape[1]:\n",
    "        tmp=0.0\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp+=A[i,k]*B[k,j]\n",
    "        C[i,j]=tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570e761-e86f-4fba-bac1-41ca39fc6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Call the kernel function and time it to get the execution time\n",
    "%timeit matmul[griddim,blockdim](A,B,C)\n",
    "print(C.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ef916-da94-4e80-ade8-2bd5592e14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Create A,B,C manually on the GPU and copy data to the GPU arrays\n",
    "d_A=cuda.to_device(A)\n",
    "d_B=cuda.to_device(B)\n",
    "d_C=cuda.to_device(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eccaac-6763-4c1a-96f6-24aac6f4a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 6: Call the kernel function and time it to get the execution time. Compare the execution times.\n",
    "%timeit matmul[griddim,blockdim](d_A,d_B,d_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861bcb7-41fc-42ef-9b46-ed60909c9879",
   "metadata": {},
   "source": [
    "### Exercise: Incrementation of array elements\n",
    "In the following exercise each element of an array is incremented : array[i] = array[i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def increment(array):\n",
    "    pos = cuda.grid(1)\n",
    "    if pos<array.size:\n",
    "        array[pos] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.ones(12800,dtype=np.int32)\n",
    "NumThreads=16\n",
    "NumBlocks = (data.size + (NumThreads - 1)) // NumThreads\n",
    "print(NumBlocks,NumThreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the kernel and measure execution time:\n",
    "%timeit increment[NumBlocks,NumThreads](data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take advatage of excplicit data management and copy an array to GPU before kernel execution. \n",
    "# Then measure the execution time again\n",
    "d_data = cuda.to_device(data)\n",
    "%timeit increment[NumBlocks,NumThreads](d_data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a45c30-e253-4788-88e9-b12c49f98629",
   "metadata": {},
   "source": [
    "### Exercise: Reversal of array elements\n",
    "Here an integer array is sent to GPU where its indices are reversed, i.e. array[0]=array[N-1], array[1]=array[N-2], etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libs\n",
    "import numpy as np\n",
    "from numba import cuda, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030599d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 3: Create a CUDA kernel with @cuda.jit decorator\n",
    "# Kernel: reverse the array content using appropriate indices. \n",
    "# To do so you may need input and output indices. Implement kernel with possibility of multiple thread blocks.\n",
    "@cuda.jit\n",
    "def reverseArray(d_out,d_in):\n",
    "    ind_in = cuda.blockDim.x*cuda.blockIdx.x + cuda.threadIdx.x; ## Index of the current thread\n",
    "    ind_out = cuda.gridsize(1)-ind_in-1 ## Total number of threads - in -1\n",
    "    if ind_in<d_in.size:\n",
    "        d_out[ind_out] = d_in[ind_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CUDA grid\n",
    "dim=256*1000\n",
    "NumThreads=128\n",
    "NumBlocks = (dim + (NumThreads - 1)) // NumThreads\n",
    "print(NumBlocks,NumThreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d18b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 1: Create arrays on CPU and GPU (if you want to)\n",
    "a = np.arange(0,dim,dtype=np.int32)\n",
    "b = np.zeros(dim,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Initialize host array\n",
    "# Already initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5be58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Call the kernel function\n",
    "%timeit reverseArray[NumBlocks,NumThreads](b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb579273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Verify the result\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Take advantage of explicit data management\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.device_array_like(b)\n",
    "%timeit reverseArray[NumBlocks,NumThreads](d_b,d_a)\n",
    "b = d_b.copy_to_host()\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
