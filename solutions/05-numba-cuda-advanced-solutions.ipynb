{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sapphire-virgin",
   "metadata": {},
   "source": [
    "# Introduction to GPU Programming with Python\n",
    "## Solutions to notebook 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac333be-e311-4a76-9028-b82d395c2d3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Main example: Matrix multiplication with shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fbb2e6-5bee-4b11-815c-b6c69a372816",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](../images/05-matmulshared.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354cd352-de7f-4466-8473-fa3baefcd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Create a CUDA kernel with @cuda.jit decorator\n",
    "\n",
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 32\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    \n",
    "    # Define global and thread indices\n",
    "    x, y = cuda.grid(2)\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    # Define number of blocks per grid\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "    \n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "    \n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "        \n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    # Put tmp into C matrix\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87463663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Create matrices A,B,C as numpy arrays (size 128x128,float32). Fill A and B with random numbers.\n",
    "N=128\n",
    "A=np.random.rand(N,N).astype(np.float32)\n",
    "B=np.random.rand(N,N).astype(np.float32)\n",
    "C=np.zeros(shape=(N,N)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Calculate number of blocks and threads\n",
    "NumThreads = TPB\n",
    "NumBlocks = N//NumThreads\n",
    "griddim = (NumBlocks,NumBlocks)\n",
    "blockdim = (NumThreads,NumThreads)\n",
    "print(blockdim)\n",
    "print(griddim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Call the kernel function and time it to get the execution time\n",
    "%timeit fast_matmul[griddim,blockdim](A, B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a82bf-3ccf-4714-86ec-9020c4635785",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise: Array reversal with shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473e8cd-7168-42c1-9e89-8e22d2a4cd99",
   "metadata": {},
   "source": [
    "Here we re-use the code from [previous notebook](../04-numba-cuda.ipynb) and add shared memory into play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe4676d-bd06-461a-beb6-8fa6eaa5eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda,int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84db54f-76c5-482a-8c9d-53fbb07cf2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Here is the code with shared memory\n",
    "@cuda.jit\n",
    "def reverseArrayBlock_shared(d_out,d_in):\n",
    "    # Declare/allocate array s in shared memory\n",
    "    # Static shared memory declaration\n",
    "    s = cuda.shared.array(2000, dtype=int32) \n",
    "    # Dynamic shared memory declaration\n",
    "    #s = cuda.shared.array(0, dtype=int32)\n",
    "    # Create input index\n",
    "    ind_in = cuda.blockDim.x*cuda.blockIdx.x + cuda.threadIdx.x; ## Index of the current thread\n",
    "    # Populate array s from arrat d_in\n",
    "    s[cuda.blockDim.x - cuda.threadIdx.x - 1] = d_in[ind_in]\n",
    "    # Synchronize threads in each block\n",
    "    cuda.syncthreads()\n",
    "    # Create output index\n",
    "    ind_out = cuda.blockDim.x*(cuda.gridDim.x - 1 - cuda.blockIdx.x) + cuda.threadIdx.x\n",
    "    if ind_in<d_in.size:\n",
    "        # Populate output array d_out from shared array s\n",
    "        d_out[ind_out] = s[cuda.threadIdx.x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afbc0b-2678-430d-a489-f1d259157726",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=256*1000\n",
    "NumThreads=128\n",
    "NumBlocks = (dim + (NumThreads - 1)) // NumThreads\n",
    "print(NumBlocks,NumThreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba551a3-eb54-48ed-af5c-0e96667f071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Create arrays on CPU and GPU (if you want to)\n",
    "a = np.arange(0,dim,dtype=np.int32)\n",
    "b = np.zeros(dim,dtype=np.int32)\n",
    "memSize = NumThreads * a.dtype.itemsize\n",
    "print(memSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a2fc1-e0b9-4bc1-8d5d-02512be342ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Call the kernel\n",
    "# Static shared memory declaration\n",
    "reverseArrayBlock_shared[NumBlocks,NumThreads](b,a)\n",
    "print(b)"
   ]
  }
  
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
