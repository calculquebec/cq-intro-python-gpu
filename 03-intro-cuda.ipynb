{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sapphire-virgin",
   "metadata": {},
   "source": [
    "# Introduction to GPU Programming with Python\n",
    "## Intro to CUDA\n",
    "\n",
    "To compile a function on the GPU we must use `numba.cuda.jit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa1bf0c-ab18-4c6f-85de-09198f33878e",
   "metadata": {},
   "source": [
    "Questions\n",
    "* What is CUDA ?\n",
    "\n",
    "Objectives\n",
    "* Learn CUDA terminology\n",
    "* Learn CUDA programming model\n",
    "* Understand what the CUDA kernel is\n",
    "* Understand the CUDA block-threading model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939b280-8a64-480a-8af4-6885105255a2",
   "metadata": {},
   "source": [
    "#### CUDA terminology\n",
    "Before we jump into CUDA with Python lets talk about CUDA terminology and main execution concept:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c1623-25a5-49c7-9f3c-74b8b23635c9",
   "metadata": {},
   "source": [
    "![](images/host_device.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99624ffa-1bfe-4fa7-b29e-bdb138d8981a",
   "metadata": {},
   "source": [
    "### CUDA Programming Model\n",
    "1. Copy data from the CPU memory to GPU memory (remember: CPU and GPU are physically separated)\n",
    "![](images/cuda_model1.png)\n",
    "\n",
    "2. Load the GPU program and execute it\n",
    "![](images/cuda_model2.png)\n",
    "\n",
    "3. Copy the results from the GPU memory back to the CPU memory (so that you could print it, get it analyzed, etc)\n",
    "![](images/cuda_model3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096fb8e-8091-4fc2-9ae3-8f469d1318fc",
   "metadata": {},
   "source": [
    "#### CUDA kernel\n",
    "We have been talking about CUDA kernels, but what is CUDA kernel ? \n",
    "![](images/cuda_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa71fbd-d324-4276-acec-51cf0c773bab",
   "metadata": {},
   "source": [
    "In CUDA we divide a program into a grid of threads, and a kernel is a program executed on each of those threads independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b19f9-deb8-482a-b82c-e8068e8433b0",
   "metadata": {},
   "source": [
    "It's different from how we create a CPU program as there we have to explicitate every operation, every loop, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de72760b-2975-41ee-a4f0-d5672d4a642a",
   "metadata": {},
   "source": [
    "Lets look at the matrix addition example.\n",
    "In the CPU implementation we would loop over all the elements of matrix A:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc89712-cad3-4626-a10d-15979b56a455",
   "metadata": {},
   "source": [
    "![](images/matrix_cpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c238f-9e74-4b83-9ffe-5c376a9dbf6d",
   "metadata": {},
   "source": [
    "![](images/matrix_gpu2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227dd4e-d364-4388-9aae-222cc0dace03",
   "metadata": {},
   "source": [
    "Unfortunately there is another layer of complexity:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0f69a-bad7-48b1-b1b6-c14d65d2a533",
   "metadata": {},
   "source": [
    "![](images/cuda_block_grid2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e6c97-b90d-4ee3-8b91-3c8b5ac3262e",
   "metadata": {},
   "source": [
    "### CUDA Execution model\n",
    "Thread Layout:\n",
    "* Threads are organized into blocks\n",
    "* Blocks are organized into a grid\n",
    "* SM executes one block at a time\n",
    "\n",
    "Each thread uses IDs to decide what data to work on:\n",
    "* Block IDs (e.g. blockIdx.x, blockIdx.y)\n",
    "* Thread Ids (threadIdx.x, threadIdx.y)\n",
    "\n",
    "Such model simplifies memory addressing when processing multidimmensional data.\n",
    "\n",
    "Simple CUDA program executed on those GPU threads is called KERNEL \n",
    "CUDA programmer is responsible for setting up a grid and tune it for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aeeb05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Choosing the block size\n",
    "\n",
    "* On the software side, the block size determines how many threads share a given area of shared memory.\n",
    "* On the hardware side, the block size must be large enough for full occupation of execution units; \n",
    "The block size you choose depends on:\n",
    "* The size of the data array\n",
    "* The size of the shared mempory per block (e.g. 64KB)\n",
    "* The maximum number of threads per block supported by the hardware (e.g. 512 or 1024)\n",
    "* The maximum number of threads per multiprocessor (MP) (e.g. 2048)\n",
    "* The maximum number of blocks per MP (e.g. 32)\n",
    "* The number of threads that can be executed concurrently (a “warp” i.e. 32)\n",
    "\n",
    "Rules of thumb for threads per block:\n",
    "\n",
    "    Should be a round multiple of the warp size (32)\n",
    "    A good place to start is 128-512 but benchmarking is required to determine the optimal value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a01d4d-0a32-4684-b9fe-45c6e564b675",
   "metadata": {},
   "source": [
    "## Key points\n",
    "* **Host and Device** \n",
    "    * Device (GPU) won't work without Host(CPU)\n",
    "    * Both Host and Device have their own memory\n",
    "* **Kernel and Device functions**\n",
    "    * Kernel is called from  the Host\n",
    "    * Device function is called from the Device.\n",
    "* **Threads, Blocks, Grids**\n",
    "    * They can be 1D, 2D, or 3D depending on data complexity\n",
    "    * Each of them has IDs: they are used to access certain portion of data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
