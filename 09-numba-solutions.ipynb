{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8df65d",
   "metadata": {},
   "source": [
    "# Introduction to GPU Programming with Python\n",
    "## Solutions to the exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f85ed",
   "metadata": {},
   "source": [
    "### Exercise 0\n",
    "Matrix multiplication using jit decorator (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2985c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit,njit\n",
    "from numba import vectorize,float64\n",
    "from numba import prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980976d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit('void(float64[:,:],float64[:,:],float64[:,:])',parallel=True)\n",
    "def matmul(A,B,C):\n",
    "    # iterating by row of A\n",
    "    for i in prange(len(A)):\n",
    "  \n",
    "        # iterating by coloum by B \n",
    "        for j in prange(len(B[0])):\n",
    "  \n",
    "            # iterating by rows of B\n",
    "            for k in range(len(B)):\n",
    "                C[i][j] += A[i][k] * B[k][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.random.rand(128,128)\n",
    "B=np.random.rand(128,128)\n",
    "C=np.zeros(shape=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit matmul(A,B,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8c026",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Lets do the following exercise where each element of an array is incremented : array[i] = array[i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def kernel1(array):\n",
    "    pos = cuda.grid(1)\n",
    "    if pos<array.size:\n",
    "        array[pos] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=numpy.ones(12800,dtype=np.int32)\n",
    "threads=32\n",
    "blocks = (data.size + (threads - 1)) // threads\n",
    "print(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the kernel and measure execution time:\n",
    "%timeit kernel1[blocks,threads](data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take advatage of excplicit data management and copy an array to GPU before kernel execution. \n",
    "# Then measure the execution time again\n",
    "d_data = cuda.to_device(data)\n",
    "%timeit kernel1[blocks,threads](d_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fececc9c",
   "metadata": {},
   "source": [
    "### Exercice 2\n",
    "Integer array, sent to GPU where its indices are reversed, i.e. array[0]=array[N-1], array[1]=array[N-2], etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de947d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libs\n",
    "import numpy as np\n",
    "from numba import cuda, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Create a CUDA kernel with @cuda.jit decorator\n",
    "# Kernel: reverse the array content using appropriate indices. \n",
    "# To do so you may need input and output indices. Implement kernel with possibility of multiple thread blocks.\n",
    "@cuda.jit\n",
    "def reverseArrayBlock(d_out,d_in):\n",
    "    ind_in = cuda.grid(1) ## Index of the current thread\n",
    "    ind_out = cuda.gridsize(1)-ind_in-1 ## Total number of threads - in -1\n",
    "    if ind_in<d_in.size:\n",
    "        d_out[ind_out] = d_in[ind_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf52c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CUDA grid\n",
    "dim=256\n",
    "NumBlocks=1\n",
    "NumThreadsPerBlock=dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Create arrays on CPU and GPU (if you want to)\n",
    "a = np.arange(0,dim,dtype=np.int32)\n",
    "b = np.zeros(dim,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1119d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Initialize host array\n",
    "# Already initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Call the kernel function\n",
    "%timeit reverseArrayBlock[NumBlocks,NumThreadsPerBlock](b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98360881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Verify the result\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Take advantage of explicit data management\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.device_array_like(b)\n",
    "%timeit reverseArrayBlock[NumBlocks,NumThreadsPerBlock](d_b,d_a)\n",
    "d_b.copy_to_host(b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2e732",
   "metadata": {},
   "source": [
    "### Exercice 3\n",
    "Repeat Excercise 2 with multiple blocks per CUDA grid (NumBlocks > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db735167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libs\n",
    "import numpy as np\n",
    "from numba import cuda, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Create a CUDA kernel with @cuda.jit decorator\n",
    "# Kernel: reverse the array content using appropriate indices. \n",
    "# To do so you may need input and output indices. Implement kernel with possibility of multiple thread blocks.\n",
    "@cuda.jit\n",
    "def reverseArrayBlock(d_out,d_in):\n",
    "    ind_in = cuda.blockDim.x*cuda.blockIdx.x + cuda.threadIdx.x; ## Index of the current thread\n",
    "    ind_out = cuda.gridsize(1)-ind_in-1 ## Total number of threads - in -1\n",
    "    if ind_in<d_in.size:\n",
    "        d_out[ind_out] = d_in[ind_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c0391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CUDA grid\n",
    "dim=256*1000\n",
    "NumThreadsPerBlock=128\n",
    "NumBlocks = (dim + (NumThreadsPerBlock - 1)) // NumThreadsPerBlock\n",
    "print(NumBlocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Create arrays on CPU and GPU (if you want to)\n",
    "a = np.arange(0,dim,dtype=np.int32)\n",
    "b = np.zeros(dim,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Initialize host array\n",
    "# Already initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5be58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Call the kernel function\n",
    "%timeit reverseArrayBlock[NumBlocks,NumThreadsPerBlock](b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb579273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Verify the result\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Take advantage of explicit data management\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.device_array_like(b)\n",
    "%timeit reverseArrayBlock[NumBlocks,NumThreadsPerBlock](d_b,d_a)\n",
    "b = d_b.copy_to_host()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a9a34b",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Polynomial evaluation on both GPU and CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09961d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Modify polynomial function to make it work with numba.cuda\n",
    "@cuda.jit\n",
    "def cuda_polyval(result, array, coeffs):\n",
    "    # Evaluate a polynomial function over an array with Horner's method.\n",
    "    # The coefficients are given in descending order.\n",
    "    i = cuda.grid(1) # equivalent to i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    val = coeffs[0]\n",
    "    for coeff in coeffs[1:]:\n",
    "        val = val * array[i] + coeff\n",
    "    result[i] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc705389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Allocate integer array (int32), size of 2048 * 1024. Also make an empty array for result, same size\n",
    "array = np.random.randn(2048 * 1024).astype(np.float32)\n",
    "coeffs = np.float32(range(1, 10))\n",
    "result = np.empty_like(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dcaffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Prepare grid\n",
    "blocks=2048\n",
    "threads=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6847bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Call the kernel and measure execution time\n",
    "%timeit cuda_polyval[blocks,threads](result, array, coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Call the built-in NumPy polynomial function  np.polyval(coeffs, array) and compare results\n",
    "numpy_result = np.polyval(coeffs, array)\n",
    "print('Maximum relative error compared to numpy.polyval:', np.max(np.abs(numpy_result - result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defff05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 6: Go back to the kernel (Part 3) and modify it to make it work on CPU with @jit\n",
    "@jit\n",
    "def host_polyval_CPU(result, array, coeffs):\n",
    "    for i in range(len(array)):\n",
    "        val = coeffs[0]\n",
    "        for coeff in coeffs[1:]:\n",
    "            val = val * array[i] + coeff\n",
    "        result[i] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19542e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit host_polyval_CPU(result, array, coeffs)\n",
    "print('Maximum relative error compared to numpy.polyval:', np.max(np.abs(numpy_result - result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba149f",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "Matrix multiplication WITH GLOBAL MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b580b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(A,B,C):\n",
    "    # iterating by row of A\n",
    "    for i in range(len(A)):\n",
    "  \n",
    "        # iterating by coloum by B \n",
    "        for j in range(len(B[0])):\n",
    "  \n",
    "            # iterating by rows of B\n",
    "            for k in range(len(B)):\n",
    "                C[i][j] += A[i][k] * B[k][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Create matrices A,B,C as numpy arrays. Fill A and B with random numbers.\n",
    "A=np.random.rand(128,128)\n",
    "B=np.random.rand(128,128)\n",
    "C=np.zeros(shape=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f792d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Calculate number of blocks and threads\n",
    "threads=32\n",
    "blocks = C.shape[0]*C.shape[1]//threads +1\n",
    "blockdim = (threads,threads)\n",
    "griddim = (blocks,blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8584e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Create a CUDA kernel with @cuda.jit decorator\n",
    "@cuda.jit\n",
    "def matmul(A,B,C):\n",
    "    i,j=cuda.grid(2)\n",
    "    if i<C.shape[0] and j<C.shape[1]:\n",
    "        tmp=0.0\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp+=A[i,k]*B[k,j]\n",
    "        C[i,j]=tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec26b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Call the kernel function and time it to get the execution time\n",
    "%timeit matmul[griddim,blockdim](A,B,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Create A,B,C manually on the GPU and copy data to the GPU arrays\n",
    "d_A=cuda.to_device(A)\n",
    "d_B=cuda.to_device(B)\n",
    "d_C=cuda.to_device(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbe63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 6: Call the kernel function and time it to get the execution time. Compare the execution times.\n",
    "%timeit matmul[blocks,threads](d_A,d_B,d_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47387fec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mandelbrot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed41ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow, show\n",
    "from timeit import default_timer as timer\n",
    "from numba import jit,cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mandel(x, y, max_iters):\n",
    "  \n",
    "  c = complex(x, y)\n",
    "  z = 0.0j\n",
    "  for i in range(max_iters):\n",
    "    z = z*z + c\n",
    "    if (z.real*z.real + z.imag*z.imag) >= 4:\n",
    "      return i\n",
    "\n",
    "  return max_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part1 : Make a create_fractal function\n",
    "def create_fractal(min_x, max_x, min_y, max_y, image, iters):\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "\n",
    "  pixel_size_x = (max_x - min_x) / width\n",
    "  pixel_size_y = (max_y - min_y) / height\n",
    "    \n",
    "  for x in range(width):\n",
    "    real = min_x + x * pixel_size_x\n",
    "    for y in range(height):\n",
    "      imag = min_y + y * pixel_size_y\n",
    "      color = mandel(real, imag, iters)\n",
    "      image[y, x] = color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ff90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Next we create an empty array, size 1024x1024, type np.uint8. Call create_fractal with appropriate coordinates \n",
    "#to fit the whole mandelbrot set. Then show the image. Measure the execution time.\n",
    "image = np.zeros((1024, 1024), dtype = np.uint8)\n",
    "%timeit create_fractal(-2.0, 1.0, -1.0, 1.0, image, 20) \n",
    "\n",
    "imshow(image)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309aed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Modify both mandel and create_fractal function and optimize/parallelize them with jit decorator \n",
    "#to work on the CPU\n",
    "@jit\n",
    "def mandel(x, y, max_iters):\n",
    "  \n",
    "  c = complex(x, y)\n",
    "  z = 0.0j\n",
    "  for i in range(max_iters):\n",
    "    z = z*z + c\n",
    "    if (z.real*z.real + z.imag*z.imag) >= 4:\n",
    "      return i\n",
    "\n",
    "  return max_iters\n",
    "\n",
    "@jit\n",
    "def create_fractal(min_x, max_x, min_y, max_y, image, iters):\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "\n",
    "  pixel_size_x = (max_x - min_x) / width\n",
    "  pixel_size_y = (max_y - min_y) / height\n",
    "    \n",
    "  for x in range(width):\n",
    "    real = min_x + x * pixel_size_x\n",
    "    for y in range(height):\n",
    "      imag = min_y + y * pixel_size_y\n",
    "      color = mandel(real, imag, iters)\n",
    "      image[y, x] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff462f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Run again and measure the execution time\n",
    "image = np.zeros((1024, 1024), dtype = np.uint8)\n",
    "%timeit create_fractal(-2.0, 1.0, -1.0, 1.0, image, 20) \n",
    "\n",
    "imshow(image)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea23f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 5: Write the kernel function mandel_kernel  with numba.cuda. Also modify mandel to mandel_gpu with cuda.jit\n",
    "mandel_gpu = cuda.jit(device=True)(mandel)\n",
    "\n",
    "@cuda.jit\n",
    "def mandel_kernel(min_x, max_x, min_y, max_y, image, iters):\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "\n",
    "  pixel_size_x = (max_x - min_x) / width\n",
    "  pixel_size_y = (max_y - min_y) / height\n",
    "\n",
    "  startX, startY = cuda.grid(2)\n",
    "  gridX = cuda.gridDim.x * cuda.blockDim.x;\n",
    "  gridY = cuda.gridDim.y * cuda.blockDim.y;\n",
    "\n",
    "  for x in range(startX, width, gridX):\n",
    "    real = min_x + x * pixel_size_x\n",
    "    for y in range(startY, height, gridY):\n",
    "      imag = min_y + y * pixel_size_y \n",
    "      image[y, x] = mandel_gpu(real, imag, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 6: Create cuda grid\n",
    "image = np.zeros((1024, 1024), dtype = np.uint8)\n",
    "blockdim = (32,8)\n",
    "griddim = (32,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe99ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 7: Run the kernel. Also measure the execution time.\n",
    "%timeit mandel_kernel[griddim,blockdim](-2.0, 1.0, -1.0, 1.0, image, 20) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f38d4",
   "metadata": {},
   "source": [
    "### Matrix multiplication WITH SHARED MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354cd352-de7f-4466-8473-fa3baefcd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Create a CUDA kernel with @cuda.jit decorator\n",
    "\n",
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 16\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    \n",
    "    # Define global and thread indices\n",
    "    x, y = cuda.grid(2)\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    # Define number of blocks per grid\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "    \n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "    \n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "        \n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    # Put tmp into C matrix\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87463663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Create matrices A,B,C as numpy arrays (size 128x128,float32). Fill A and B with random numbers.\n",
    "N=128\n",
    "A=np.random.rand(N,N).astype(np.float32)\n",
    "B=np.random.rand(N,N).astype(np.float32)\n",
    "C=np.zeros(shape=(N,N)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Calculate number of blocks and threads\n",
    "griddim = (N//TPB,N//TPB)\n",
    "blockdim = (TPB,TPB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Call the kernel function and time it to get the execution time\n",
    "%timeit fast_matmul[griddim,blockdim](A, B, C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
